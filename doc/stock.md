<h1>Idea of AI Stock Modeling</h1>

## To Do list
### Classified (man labeled buy/sell)
* use savgol_filter() to smooth data before calculate velocity & acceleration(compare with SMA)
* try different NN model (GRU, ...)
* try different activate functions (relu, sigmoid, ...)
* try different loss functions ()
* try different optimizers ()
* testing on real data (å®æ“)

### Future forecast
* backtesting on our own data
* testing on real data (å®æ“)


1. use boolinger line to determine long/short points(max:long, min:short value)
2. smooth (9, 15) all data, use the smoothed data as close[array]
3. calculate vilocity for all points(array)
4. calculate accelerate for all points(array)
5. use a window find stock input smooth data
6. create datasets:
   a. input(close, vilocity, accelerate, weekdays, time, volume)
   b. output(long, short)
7. create model
8. use the model to test training data


<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [To Do list](#to-do-list)
  - [Classified (man labeled buy/sell)](#classified-man-labeled-buysell)
  - [Future forecast](#future-forecast)
- [Idea of selecting long,short,hold points](#idea-of-selecting-longshorthold-points)
- [To-do list:](#to-do-list-1)
  - [Data Normalization](#data-normalization)
- [Create datasets](#create-datasets)
- [save and load datasets from file](#save-and-load-datasets-from-file)
- [velocity and acceleration](#velocity-and-acceleration)
- [Training and test data design](#training-and-test-data-design)
- [Add Weights on Data](#add-weights-on-data)
- [Add hold as output as \[long, hold, short\]](#add-hold-as-output-as-long-hold-short)
- [Available Models](#available-models)
  - [å·ç§¯ç¥ç»ç½‘ç»œ](#å·ç§¯ç¥ç»ç½‘ç»œ)
  - [Recurrent Neural Network](#recurrent-neural-network)
  - [Attension Machanics](#attension-machanics)
  - [Transform æ¨¡å‹](#transform-æ¨¡å‹)
  - [AutoEncoders](#autoencoders)
  - [ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ](#ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ)
  - [Reinforcement Learning](#reinforcement-learning)
- [AIæ— æ³•å­¦ä¹ çš„æ•°æ®å½¢æ€](#aiæ— æ³•å­¦ä¹ çš„æ•°æ®å½¢æ€)
- [å¯å˜é•¿çš„æ—¶é—´åºåˆ—](#å¯å˜é•¿çš„æ—¶é—´åºåˆ—)
- [GRU model](#gru-model)
- [Load Stock Data to sqlite database](#load-stock-data-to-sqlite-database)
  - [Generate Training \& Testing Data](#generate-training--testing-data)
  - [Create a GRU model](#create-a-gru-model)
  - [Forcast Future Stock Price Range](#forcast-future-stock-price-range)
- [Activate Functions](#activate-functions)

<!-- /code_chunk_output -->



## Idea of selecting long,short,hold points

ğŸ› ğŸ¯ Leave this section for å‘¨æµ©,é©¬å¤´å„¿

* IPO (input, process, output)
* AI training: from tensor to token
* Prepare tensor (training data and testing data)

* Concern and Issuesï¼Œsolution
  1. simplify and efficiency we choos nasdaq 100 future only.
  2. one minuts data maybe enough
  3. day trading or swing trading
  4. 20 or 30 points as base rule
  5. try Zigzag get training data long/short points
  6. another way to find valley and peak is find edge between MACD cross.


~~æœ€è¿‘ä¸¤ä¸ªæœˆä»¥æ¥æˆ‘ä¸€ç›´ä¸ºé€‰æ‹©ç†æƒ³çš„ä¹°å–ç‚¹è€Œè‹¦æ¼ï¼Œå°è¯•è¿‡å¤šç§æ–¹æ³•éƒ½ä¸ç†æƒ³ã€‚åˆ°ç°åœ¨æˆ‘ä»¬ç”¨çš„éƒ½æ˜¯â€œdirty and quick"çš„æ–¹æ³•é€‰æ‹©å‡ºæ¥çš„ç‚¹ï¼šåœ¨åˆé€‰å‡ºæ¥çš„æœ€ä½æœ€é«˜ç‚¹ä¸­é€‰ç›¸é‚»çš„äº”ç‚¹ï¼Œå‘å‰çœ‹ä¸¤æ­¥ï¼Œå‘åçœ‹ä¸‰æ­¥ï¼Œå¦‚æœå½“å‰ç‚¹æ˜¯åˆé€‰å‡ºæ¥çš„ä½ç‚¹é‡Œé¢çš„ç›¸å¯¹æœ€ä½ï¼Œå°±é€‰ä½œä¹°ç‚¹ï¼›åä¹‹ï¼Œå¦‚æœæ˜¯åˆé€‰å‡ºæ¥çš„é«˜ç‚¹é‡Œé¢çš„ç›¸å¯¹æœ€é«˜ï¼Œåˆ™é€‰æ‹©å‡ºæ¥åšå–ç‚¹ã€‚
è¿™ç§é€‰æ³•ä¼šå‡ºç°è¿™æ ·çš„é—®é¢˜ï¼š~~

![AåŒºä¸BåŒºç›¸æ¯”è¾ƒï¼ŒAåŒºä¸åˆç†](images/SPYHighLow0409-0531.jpg)

~~çœ‹Açª—å’ŒBçª—ã€‚å› ä¸ºé€‰æ‹©æ ‡å‡†æ˜¯åœ¨ç›¸é‚»çš„åˆé€‰é«˜ä½ç‚¹é‡Œé¢é€‰æ‹©ï¼Œåœ¨AåŒºï¼ŒçŸ®å­é‡Œé¢é€‰å°†å†›é€‰å‡ºçš„é‚£äº›ç‚¹åœ¨BåŒºå…¶å®æ˜¯å®Œå…¨ä¸ä¼šå…¥é€‰çš„ã€‚åœ¨å¢åŠ äº†ä¸ä½œä¸ºçš„HOLDç‚¹åè®©äº‹æƒ…æ›´åŠ å›°æƒ‘ï¼šåœ¨BåŒºéšä¾¿é€‰å‡ºæ¥çš„å‡ ä¸ªä¸ä½œä¸ºçš„HOLDç‚¹å…¶å®éƒ½ä¼šæ¯”AåŒºé‡Œé¢ä¸­é€‰çš„æ›´åˆé€‚ä¹°å–ã€‚
æˆ‘åˆå°è¯•è¿‡ç”¨MACDåŠ RSIç­‰ç­‰æ–¹æ³•æ¥é€‰æ‹©ä¹°å–çš„ï¼Œæ•ˆæœä¹Ÿä¸ç†æƒ³ã€‚å•å•ç”¨MACDé€‰æ‹©ä¾ç„¶å¤ªç²—ç³™ï¼Œä¸ç†æƒ³ï¼›å¢åŠ RSIåçº¦æŸæ¡ä»¶åˆè¿‡ä¸¥ï¼Œå‡ å¹´æ—¶é—´æ®µé‡Œé¢å±…ç„¶éƒ½å¾ˆéš¾æ‰¾åˆ°å‡ ä¸ªä¹°å–ç‚¹ã€‚
æˆ‘å› æ­¤åæ€ï¼š æ— è®ºæ˜¯ç°åœ¨ç”¨çš„å“ªç§æ–¹æ³•ï¼Œä¾ç„¶éƒ½æ˜¯æˆ‘å¸¸è¯´çš„AIå‰çš„â€œå¤å…¸æ–¹æ³•â€ï¼Œè¿™äº›éƒ½ä¸æ˜¯äº‹ç‰©çš„æœ¬è´¨ï¼Œè€Œåªæ˜¯åœ¨ä¸ºäº†å¸®åŠ©äº¤æ˜“è€Œæ€»ç»“å‡ºçš„ä¸€äº›æ–¹æ³•ï¼Œå¦‚åŒå‡ ä½•å­¦é‡Œé¢ç”»çš„è¾…åŠ©çº¿ï¼Œä¸æ˜¯æœ¬è´¨ï¼Œåªæ˜¯è¾…åŠ©ã€‚å¦‚æœæˆ‘ä»¬å›å½’äº‹ç‰©çš„æœ¬è´¨ï¼Œäº¤æ˜“ä¸­â€œä½ä¹°é«˜å–â€ï¼Œå·®é¢è¶Šå¤§è¶Šå¥½ï¼Œå¦‚æ­¤è€Œå·²ã€‚
å¦‚æœå®Œå…¨ç­‰æˆ‘ç”¨â€å¤å…¸æ–¹æ³•â€œæ¥é€‰ç‚¹åšæ•™ææ¥è®­ç»ƒAIæ¨¡å‹ï¼Œé‚£å®Œå…¨æ²¡æœ‰å‘æŒ¥æœºå™¨å­¦ä¹ çš„æ•ˆç‡å’Œä¼˜åŠ¿ï¼Œåº”è¯¥æ¢æ€è·¯ï¼Œç»™å‡ºæœ€åŸºæœ¬çš„â€œå…¬ç†â€â€œè§„åˆ™ruleâ€åæ”¾æ‰‹è®©æœºå™¨è‡ªå·±å»æŒ–æ˜å­¦ä¹ ã€‚~~

ç°åœ¨çš„æ–°ç®—æ³•é€‰æ‹©å‡ºæ¥çš„ç‚¹æ¯”å‰é¢ç”¨çš„æ•ˆæœå¥½å¾ˆå¤šï¼Œä»¥å‰çš„æ‹…å¿ƒä¸å¤å­˜åœ¨ã€‚
ç°åœ¨çš„é€‰ç‚¹å¾ˆç®€å•ï¼Œç”¨ZigZag ç®—æ³•ï¼ˆpeak_valley_pivotså‡½æ•°ï¼‰é€‰å‡ºæ‰€æœ‰çš„â€œå±±å³°â€å’Œâ€œå³¡è°·â€ï¼Œå…¶ä¸­å¯¹ä¸åŒçš„æ•°æ®é€‰ç”¨åˆé€‚çš„deviation (minimum relative change necessary to define a peak/valley) æ˜¯éå¸¸å…³é”®çš„ä¸€æ­¥ã€‚[ä¸¾ä¸€ä¸ªä¾‹å­](../src/TestPeakValleys.py), é€‰ç”¨ä¸åŒçš„deviation, æ•°å­—è¶Šå¤§ï¼Œè¢«é€‰ä¸­çš„ç‚¹è¶Šå°‘ï¼›æ•°å­—è¶Šå°ï¼Œè¢«é€‰ä¸­çš„ç‚¹è¶Šå¤šï¼š
![](images/PeakValleyDeviation.jpg)

1ï¼‰ é€‰ä¸­äº†é€‚å½“çš„deviationåï¼Œå¯ä»¥é€‰æ‹©å‡ºåˆé€‚ç–å¯†åº¦çš„peak/valleyç‚¹ï¼Œè¿™æ˜¯ç¬¬ä¸€æ­¥
![](images/ZigZag%20sample%2001.jpg)

2ï¼‰ åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè¯†åˆ«å‡ºLL(Lower Low), HH(Higher High), LH(Lower High), HL(Higher Low)æ¨¡å¼ã€‚
![](images/Ziazag%20sample%2002.jpg)

å…·ä½“æ“ä½œæ–¹æ³•æ˜¯ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªLLç‚¹ä¹°å…¥ï¼Œç„¶ååªçœ‹æ¨¡å¼çš„ç¬¬äºŒä¸ªå­—ç¬¦ï¼Œåªè¦æ˜¯Hå°±æ˜¯å–å‡ºç‚¹ï¼›å†å¾€åï¼Œåªè¦æ˜¯Lå°±æ˜¯ä¹°å…¥ç‚¹ï¼›å¦‚æ­¤å¾€å¤ï¼Œç›´åˆ°æœ€ç»ˆã€‚



è¿™é‡Œæœ‰ä¸€ä¸ªå®Œæ•´çš„å¯»æ‰¾æœ€ä½³çš„deviationçš„ä¾‹å­ï¼šé‡‡ç”¨2023å¹´SPXä¸€åˆ†é’Ÿæ•°æ®ï¼Œæ•°æ®æ€»é‡è¿‘30ä¸‡ï¼Œå‡å®šåªå•çº¯çš„ä¹°ä½å–é«˜ï¼Œæ¯ä¸€å•çš„æˆæœ¬2ç¾å…ƒã€‚ä¸æ–­çš„è°ƒæ•´deviationçš„å€¼ï¼Œæœ€åæ‰¾åˆ°æœ€ä½³çš„deviationå€¼åœ¨ä¸‡åˆ†ä¹‹4.7å·¦å³ï¼Œç›ˆåˆ©è¿‘3ä¸‡5åƒç‚¹ã€‚
[å‚è€ƒæºç¨‹åº](../src/BestTradingFraqStudy.py)
æ³¨æ„ï¼š æœ¬ç¨‹åºä¸­åªå•çº¯çš„ç”¨äº†1åˆ†é’Ÿçš„æ•°æ®ç®—å‡ºzigzagç‚¹ï¼Œå¹¶æ²¡æœ‰ç”¨5åˆ†é’Ÿçš„zigzagç‚¹æ¥è¿‡æ»¤ï¼

```dos

Deviation: 0.01         OHLC len:291380     Zigzag points:158       Total:7030.18
Deviation: 0.001        OHLC len:291380     Zigzag points:6888      Total:29806.09
Deviation: 0.0001       OHLC len:291380     Zigzag points:80882     Total:1173.18
Deviation: 0.00005      OHLC len:291380     Zigzag points:116714    Total:-29882.00

Deviation: 0.0015       OHLC len:291380     Zigzag points:3702      Total:24816.72
Deviation: 0.001        OHLC len:291380     Zigzag points:6888      Total:29806.09
Deviation: 0.0009       OHLC len:291380     Zigzag points:8030      Total:30948.83

Deviation: 0.001        OHLC len:291380     Zigzag points:6888      Total:29806.09
Deviation: 0.0008       OHLC len:291380     Zigzag points:9456      Total:32075.92
Deviation: 0.0006       OHLC len:291380     Zigzag points:14058     Total:34218.01

Deviation: 0.0005       OHLC len:291380     Zigzag points:17778     Total:34809.02
Deviation: 0.0004       OHLC len:291380     Zigzag points:23028     Total:34551.48
Deviation: 0.0003       OHLC len:291380     Zigzag points:31648     Total:32293.35


Deviation: 0.00055      OHLC len:291380     Zigzag points:15774     Total:34583.17
Deviation: 0.0005       OHLC len:291380     Zigzag points:17778     Total:34809.02
Deviation: 0.00045      OHLC len:291380     Zigzag points:20088     Total:34833.88

Deviation: 0.00049      OHLC len:291380     Zigzag points:18288     Total:34836.92
Deviation: 0.00048      OHLC len:291380     Zigzag points:18818     Total:34846.13
Deviation: 0.00047      OHLC len:291380     Zigzag points:19188     Total:34849.77
Deviation: 0.00046      OHLC len:291380     Zigzag points:19566     Total:34846.55

Deviation: 0.00048      OHLC len:291380     Zigzag points:18818     Total:34846.13
Deviation: 0.00045      OHLC len:291380     Zigzag points:20088     Total:34833.88
Deviation: 0.00042      OHLC len:291380     Zigzag points:21932     Total:34688.60

Deviation: 0.0004       OHLC len:291380     Zigzag points:23028     Total:34551.48
Deviation: 0.00035      OHLC len:291380     Zigzag points:26940     Total:33754.56
Deviation: 0.0003       OHLC len:291380     Zigzag points:31648     Total:32293.35

```

å¯¹äº2022å¹´çš„SPXä¸€åˆ†é’Ÿæ•°æ®ï¼Œæ•°æ®æ€»é‡34ä¸‡ï¼Œ åŒç­‰çš„æƒ…å†µï¼Œæœ€ä½³deviationæ˜¯ä¸‡åˆ†ä¹‹4.9, ç›ˆåˆ©9ä¸‡å¤šç‚¹ã€‚

```dos

Deviation: 0.0008       OHLC len:341611     Zigzag points:24549     Total:85548.25
Deviation: 0.0007       OHLC len:341611     Zigzag points:28645     Total:87702.47
Deviation: 0.0006       OHLC len:341611     Zigzag points:34023     Total:89393.88

Deviation: 0.00055      OHLC len:341611     Zigzag points:37281     Total:89958.20
Deviation: 0.0005       OHLC len:341611     Zigzag points:41170     Total:90209.82
Deviation: 0.00045      OHLC len:341611     Zigzag points:45526     Total:90064.73

Deviation: 0.00049      OHLC len:341611     Zigzag points:41966     Total:90224.18
Deviation: 0.00048      OHLC len:341611     Zigzag points:42792     Total:90218.15
Deviation: 0.00047      OHLC len:341611     Zigzag points:43650     Total:90189.25
Deviation: 0.00046      OHLC len:341611     Zigzag points:44508     Total:90140.42
```

å¯¹äº2021å¹´SPXä¸€åˆ†é’Ÿæ•°æ®ï¼Œæ•°æ®æ€»é‡33ä¸‡ï¼Œæœ€è¿‘deviationæ˜¯ä¸‡åˆ†ä¹‹4.5

```dos

Deviation: 0.00065      OHLC len:332576     Zigzag:14989    Total:38757.90
Deviation: 0.0006       OHLC len:332576     Zigzag:16589    Total:39274.09
Deviation: 0.00055      OHLC len:332576     Zigzag:18515    Total:39689.07
Deviation: 0.0005       OHLC len:332576     Zigzag:21037    Total:39938.19
Deviation: 0.00045      OHLC len:332576     Zigzag:23859    Total:39944.20
Deviation: 0.0004       OHLC len:332576     Zigzag:27103    Total:39642.27
Deviation: 0.0003       OHLC len:332576     Zigzag:37175    Total:36961.69
```

åœ¨äº¤æ˜“æˆæœ¬ç¨³å®šçš„æƒ…å†µä¸‹ï¼Œ3å¹´çš„deviationä¹Ÿç›¸å½“çš„ç¨³å®šï¼Œåœ¨ä¸‡åˆ†ä¹‹5åˆ°4.5ä¹‹é—´ã€‚

åœ¨äº¤æ˜“æˆæœ¬å›ºå®šçš„æƒ…å†µä¸‹ï¼Œè®¡ç®—æœºå¦‚æœçœŸçš„èƒ½æ¯ç¬”äº¤æ˜“éƒ½æˆåŠŸï¼Œå®ƒè‡ªç„¶ä¼šé‡‡å–ç›¸å½“é¢‘ç¹äº¤æ˜“çš„åŠæ³•ï¼Œèšæ²™æˆå¡”ã€‚æˆ‘ä»¬å¯ä»¥çœ‹ä¸€çœ‹æŒ‰ä¸‡åˆ†ä¹‹5å·¦å³çš„å€¼äº§ç”Ÿçš„Zigzagç‚¹ï¼Œéå¸¸éå¸¸å¯†é›†ï¼Œè¿œæ¯”å‰é¢ä¾‹å­é‡Œé¢æˆ‘é€‰æ‹©çš„è¦å¯†é›†ã€‚è¿™æ˜¯éå¸¸è‡ªç„¶çš„é€‰æ‹©ã€‚

![alt text](images/ZigZag_dense_patterns_01.jpg)

![alt text](images/ZigZag_dense_patterns_02.jpg)

![alt text](images/ZigZag_dense_patterns_03.jpg)

![alt text](images/ZigZag_dense_patterns_05.jpg)


* [Generating training and testing dataset to csv file](../src/GenTrainTestData.py)

```dos
Useful parameters 

1. IsDebug:ã€€æ‰“å¼€ï¼å…³é—­è°ƒè¯•ä¿¡æ¯ã€‚åœ¨è°ƒè¯•é˜¶æ®µç‰¹åˆ«æœ‰ç”¨;
2. SN: Serial number for different datasetï¼šã€€ç”Ÿæˆçš„è®­ç»ƒï¼æµ‹è¯•æ•°æ®é›†çš„åºåˆ—å·;
3. tdLen:ã€€è®­ç»ƒï¼æµ‹è¯•æ•°æ®çš„é•¿åº¦;
4. symbol: å¤„ç†çš„è‚¡ç¥¨çš„ç¬¦å·;
5. table_name: ä»æ•°æ®åº“ä¸­æŸ¥è¯¢æ•°æ®çš„è¡¨åã€‚
6. data_dir: æ•°æ®æ–‡ä»¶ç›®å½•å
7. training_start_date: è®­ç»ƒæ•°æ®å¼€å§‹æ—¥æœŸ
8. training_end_dateï¼š è®­ç»ƒæ•°æ®ç»ˆæ­¢æ—¥æœŸ
9. testing_start_dateï¼šæµ‹è¯•æ•°æ®å¼€å§‹æ—¥æœŸ
10. testing_end_dateï¼š æµ‹è¯•æ•°æ®ç»ˆæ­¢æ—¥æœŸ

ä¸Šè¿°çš„å‚æ•°è®¾å®šåï¼Œå°†æŒ‰ç…§å¦‚ä¸‹æ ¼å¼ç”Ÿæˆçš„è®­ç»ƒæ•°æ®ï¼š
td_file = os.path.join(data_dir, f"{symbol}_TrainingData_{tdLen}_{SN}.csv")

å®ä¾‹ï¼šSPYçª—å£å®½åº¦ä¸º50çš„ç¬¬30å·è®­ç»ƒæ•°æ®é›†
SPY_TestingData_50_30.csv
æƒ³å¯¹åº”çš„å°±æœ‰æµ‹è¯•æ•°æ®é›†
SPY_TestingData_50_30.csv
```

## To-do list:
1. å¢åŠ è®­ç»ƒæ•°æ®çš„column: ï¼ˆ MACD = EMAï¼ˆ12ï¼‰- EMA(26)ï¼›
2. å¯¹MACDæ•°æ®åšEMA(9)çš„æ›²çº¿ï¼›
3. å¢åŠ è®­ç»ƒæ•°æ®columnï¼š MACD- EMA(9)
4. è¿‡æ»¤ï¼š box / ç®±ä½“ ï¼ˆå¹…åº¦ä¸åˆ°20çš„ç‚¹è¿‡æ»¤æ‰ï¼‰
5. ä½¿ç”¨å·ç§¯æ¨¡å‹å®Œæˆè®­ç»ƒ

![](images/ml.png)
![](images/ml_process.png)
>
### Data Normalization

It is generally a good practice to normalize the input features, including price, when training a machine learning model for stock prediction. Normalization helps to scale the features to a similar range, which can improve the convergence of the model during training and prevent certain features from dominating others. Normalizing the input features can also make the model more robust to changes in the scale of the data.

However, the specific choice of normalization method can depend on the characteristics of your data and the model you are using. Common normalization techniques include min-max scaling (scaling to a range of [0, 1]) or standardization (scaling to have mean 0 and standard deviation 1). Experimenting with different normalization methods and observing the impact on the model's performance can help you determine the best approach for your stock prediction task.

## Create datasets

* [create datasets from stock raw data](../src/datasets.py)
* [Generating training and test data save to ...](../src/GenTrainTestData.py)
![](images/genTrainTestData-1.png)
![](images/genTrainTestData-2.png)
![](images/genTrainTestData-3.png)
![](images/genTrainTestData-4.png)

[](../src/GenTrainTestDataBig.py)
1. data/stock_bigdata_2019-2023.db
![](images/genTrainTestDataBig-1.png)
![alt text](images/genTrainTestDataBig-2.png)
![alt text](images/genTrainTestDataBig-3.png)
![alt text](images/genTrainTestDataBig-4.png)


## save and load datasets from file

* better file format

```csv
long,short,[(weekdays,time,close,slope,accelerate,volume),(...)]
0.1,0.2,0.3,0.4,0.5,0.6,0.7
0.2,0.3,0.4,0.5,0.6,0.8,0.9
0.3,0.4,0.5,0.6,0.7,0.5,0.4
...
```

## velocity and acceleration

$$v_i=\frac {c_{i+1}-c_{i-1}} {t_{i+1}-t_{i-1}}$$
i.e. the velocity at $t_i$ equals the difference of the "close" at $t_{i+1}$ and $t_{i-1}$. same as accelerate as below:
$$a_i=\frac {v_{i+1}-v_{i-1}} {t_{i+1}-t_{i-1}}$$

## Training and test data design

* csv file format
```
long,short,weekdays,time,price,volume,velocity,acceleration,...
1,0,2.0,10.0,503.039,2.3,0.12,1232,2.0,10.123,503.3,2.1,0.3,1354,...
1,0,2.0,10.0,503.039,2.3,0.12,1232,2.0,10.123,503.3,2.1,0.3,1354,...
... ...
```
[sample data file](../data/SPY_TraningData06.csv)
Sample format:
```csv
long,short,weekday,time,price,volume,velocity,acceleration,... ...
1,0,4.0000,10.1167,513.3700,230304.0000,-0.0600,0.1100,4.0000,10.1333,513.2700,389610.0000,-0.1000,-0.0400,4.0000,10.1500,513.2300,116196.0000,-0.0400,0.0600,4.0000,10.1667,513.0700,125490.0000,-0.1600,-0.1200,4.0000,10.1833,512.9400,308380.0000,-0.1300,0.0300,4.0000,10.2000,512.8300,153775.0000,-0.1100,0.0200,4.0000,10.2167,512.9300,191395.0000,0.1000,0.2100,4.0000,10.2333,512.7600,186673.0000,-0.1700,-0.2700,4.0000,10.2500,512.5800,243147.0000,-0.1800,-0.0100,4.0000,10.2667,512.3400,222841.0000,-0.2400,-0.0600
1,0,5.0000,15.1167,509.5700,91117.0000,-0.0400,-0.0500,5.0000,15.1333,509.5500,153922.0000,-0.0200,0.0200,5.0000,15.1500,509.4800,136941.0000,-0.0700,-0.0500,5.0000,15.1667,509.5900,115541.0000,0.1100,0.1800,5.0000,15.1833,509.5900,146988.0000,0.0000,-0.1100,5.0000,15.2000,509.5700,122923.0000,-0.0200,-0.0200,5.0000,15.2167,509.4300,163968.0000,-0.1400,-0.1200,5.0000,15.2333,509.3400,110492.0000,-0.0900,0.0500,5.0000,15.2500,509.2600,243777.0000,-0.0800,0.0100,5.0000,15.2667,509.2000,151465.0000,-0.0600,0.0200
...
0,1,4.0000,11.2333,503.6100,50585.0000,0.0400,0.0500,4.0000,11.2500,503.7300,168161.0000,0.1200,0.0800,4.0000,11.2667,503.8700,92983.0000,0.1400,0.0200,4.0000,11.2833,503.9000,221729.0000,0.0300,-0.1100,4.0000,11.3000,503.8400,129542.0000,-0.0600,-0.0900,4.0000,11.3167,503.7500,130294.0000,-0.0900,-0.0300,4.0000,11.3333,503.8200,84013.0000,0.0700,0.1600,4.0000,11.3500,503.9100,49237.0000,0.0900,0.0200,4.0000,11.3667,503.9600,259312.0000,0.0500,-0.0400,4.0000,11.3833,503.9700,92385.0000,0.0100,-0.0400
0,1,4.0000,15.4333,499.7100,180733.0000,0.0600,0.0000,4.0000,15.4500,499.7700,130763.0000,0.0600,0.0000,4.0000,15.4667,499.8200,110770.0000,0.0500,-0.0100,4.0000,15.4833,499.7900,105657.0000,-0.0300,-0.0800,4.0000,15.5000,499.8400,224877.0000,0.0500,0.0800,4.0000,15.5167,499.9200,147421.0000,0.0800,0.0300,4.0000,15.5333,499.9700,269021.0000,0.0500,-0.0300,4.0000,15.5500,500.0700,131807.0000,0.1000,0.0500,4.0000,15.5667,500.1400,149343.0000,0.0700,-0.0300,4.0000,15.5833,500.2500,164901.0000,0.1100,0.0400

```
* training dataset format
trainingDataset.shape = [18,6,10]

```py
outputs_tensor = torch.tensor(outputs).reshape(18,2)
inputs_tensor = torch.tensor(inputs).reshape(18,1,6,10)
```
where
1. 18 is total number of training data.
2. 2 in outputs_tensor is 1 demension 2 items array, ['long', 'short'].
3. 6 in inputs_tensor is 6 columns as (weekdays,time,close,velocity,acceleration,volume).
4. 10 in inputs_tensor is window size, which means we start from current time backwards for 10 data.

Sample input tensor
```
tensor([[[ 4.0000e+00,  1.0117e+01,  5.1337e+02,  ...,  1.0133e+01,
           5.1327e+02,  3.8961e+05],
         [-1.0000e-01, -4.0000e-02,  4.0000e+00,  ...,  6.0000e-02,
           4.0000e+00,  1.0167e+01],
         [ 5.1307e+02,  1.2549e+05, -1.6000e-01,  ...,  3.0838e+05,
          -1.3000e-01,  3.0000e-02],
         [ 4.0000e+00,  1.0200e+01,  5.1283e+02,  ...,  1.0217e+01,
           5.1293e+02,  1.9140e+05],
         [ 1.0000e-01,  2.1000e-01,  4.0000e+00,  ..., -2.7000e-01,
           4.0000e+00,  1.0250e+01],
         [ 5.1258e+02,  2.4315e+05, -1.8000e-01,  ...,  2.2284e+05,
          -2.4000e-01, -6.0000e-02]],

        [[ 5.0000e+00,  1.5117e+01,  5.0957e+02,  ...,  1.5133e+01,
           5.0955e+02,  1.5392e+05],
         [-2.0000e-02,  2.0000e-02,  5.0000e+00,  ..., -5.0000e-02,
           5.0000e+00,  1.5167e+01],
         [ 5.0959e+02,  1.1554e+05,  1.1000e-01,  ...,  1.4699e+05,
           0.0000e+00, -1.1000e-01],
         [ 5.0000e+00,  1.5200e+01,  5.0957e+02,  ...,  1.5217e+01,
           5.0943e+02,  1.6397e+05],
         [-1.4000e-01, -1.2000e-01,  5.0000e+00,  ...,  5.0000e-02,
           5.0000e+00,  1.5250e+01],
         [ 5.0926e+02,  2.4378e+05, -8.0000e-02,  ...,  1.5146e+05,
          -6.0000e-02,  2.0000e-02]],

        [[ 2.0000e+00,  1.0483e+01,  5.0329e+02,  ...,  1.0500e+01,
           5.0327e+02,  2.2177e+05],
         [-2.0000e-02,  9.0000e-02,  2.0000e+00,  ...,  2.0000e-02,
           2.0000e+00,  1.0533e+01],
         [ 5.0323e+02,  1.0411e+05, -4.0000e-02,  ...,  2.6403e+05,
          -8.0000e-02, -4.0000e-02],
         [ 2.0000e+00,  1.0567e+01,  5.0315e+02,  ...,  1.0583e+01,
           5.0307e+02,  9.7668e+04],
         [-8.0000e-02, -8.0000e-02,  2.0000e+00,  ..., -1.0000e-01,
           2.0000e+00,  1.0617e+01],
         [ 5.0271e+02,  2.7079e+05, -1.8000e-01,  ...,  1.4372e+05,
          -3.0000e-02,  1.5000e-01]],

        ...,

        [[ 3.0000e+00,  1.4600e+01,  5.0168e+02,  ...,  1.4617e+01,
           5.0171e+02,  7.9677e+04],
         [ 3.0000e-02,  1.3000e-01,  3.0000e+00,  ...,  9.0000e-02,
           3.0000e+00,  1.4650e+01],
         [ 5.0207e+02,  9.1089e+04,  2.4000e-01,  ...,  9.8564e+04,
           3.2000e-01,  8.0000e-02],
         [ 3.0000e+00,  1.4683e+01,  5.0288e+02,  ...,  1.4700e+01,
           5.0323e+02,  4.1820e+05],
         [ 3.5000e-01, -1.4000e-01,  3.0000e+00,  ..., -1.0000e-02,
           3.0000e+00,  1.4733e+01],
         [ 5.0372e+02,  2.0590e+05,  1.5000e-01,  ...,  2.3435e+05,
           1.8000e-01,  3.0000e-02]],

        [[ 4.0000e+00,  1.1233e+01,  5.0361e+02,  ...,  1.1250e+01,
           5.0373e+02,  1.6816e+05],
         [ 1.2000e-01,  8.0000e-02,  4.0000e+00,  ...,  2.0000e-02,
           4.0000e+00,  1.1283e+01],
         [ 5.0390e+02,  2.2173e+05,  3.0000e-02,  ...,  1.2954e+05,
          -6.0000e-02, -9.0000e-02],
         [ 4.0000e+00,  1.1317e+01,  5.0375e+02,  ...,  1.1333e+01,
           5.0382e+02,  8.4013e+04],
         [ 7.0000e-02,  1.6000e-01,  4.0000e+00,  ...,  2.0000e-02,
           4.0000e+00,  1.1367e+01],
         [ 5.0396e+02,  2.5931e+05,  5.0000e-02,  ...,  9.2385e+04,
           1.0000e-02, -4.0000e-02]],

        [[ 4.0000e+00,  1.5433e+01,  4.9971e+02,  ...,  1.5450e+01,
           4.9977e+02,  1.3076e+05],
         [ 6.0000e-02,  0.0000e+00,  4.0000e+00,  ..., -1.0000e-02,
           4.0000e+00,  1.5483e+01],
         [ 4.9979e+02,  1.0566e+05, -3.0000e-02,  ...,  2.2488e+05,
           5.0000e-02,  8.0000e-02],
         [ 4.0000e+00,  1.5517e+01,  4.9992e+02,  ...,  1.5533e+01,
           4.9997e+02,  2.6902e+05],
         [ 5.0000e-02, -3.0000e-02,  4.0000e+00,  ...,  5.0000e-02,
           4.0000e+00,  1.5567e+01],
         [ 5.0014e+02,  1.4934e+05,  7.0000e-02,  ...,  1.6490e+05,
           1.1000e-01,  4.0000e-02]]])
```

sample training output tensor

```
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
```
index=0, è¡¨æ˜è¯¥çª—å£æ•°æ®å±äºlongç±»ã€‚index=1ï¼Œè¡¨é¢è¯¥çª—å£æ•°æ®å±äºshortç±»ã€‚

é¢„æµ‹ç»“æœå®ä¾‹ï¼š
predict=[-0.27,3.45]
ç”±äºindex=1çš„æ•°å­—æ›´å¤§ï¼Œè¡¨æ˜è¯¥è¾“å…¥æ•°æ®è¢«è®¤å®šä¸ºshortã€‚

* test dataset format
test datasets å’Œtraining datasetsä¸¤è€…çš„è¾“å…¥ç»“æ„æ˜¯ç›¸åŒçš„ï¼Œä½†æ˜¯è¾“å‡ºçš„ç»“æ„æ˜¯ä¸åŒçš„ã€‚å¯¹äºè®­ç»ƒç”¨çš„æ•°æ®ï¼Œè¾“å‡ºéƒ¨åˆ†ä¹Ÿæ˜¯ä¸€ä¸ªäºŒç»´çŸ©é˜µï¼ˆè§ä¸Šé¢çš„å®é™…ä¾‹å­ï¼‰ï¼Œè¡¨ç¤ºè¯¥ç»™å®šçª—å£æ•°æ®çš„åˆ†ç±»ï¼Œæˆ–è€…æ˜¯longï¼Œæˆ–è€…æ˜¯shortï¼Œç”¨[1,0]è¡¨ç¤ºè®¾å®šä¸ºlongï¼Œç”¨[0,1]è®¾å®šä¸ºshortã€‚
è€Œtestæ•°æ®çš„è¾“å‡ºï¼Œåªæ˜¯ä¸€ä¸ªä¸€ç»´çŸ©é˜µï¼ŒåŒ…å«æ¯ä¸ªçª—å£çš„æ­£ç¡®ç»“æœæ‰€å¤„çš„ä½ç½®ï¼ˆindexï¼‰ã€‚å¯¹äºä¸Šé¢ç»™å‡ºçš„18è¡Œçš„æ•°æ®ï¼Œæµ‹è¯•Tensorçœ‹èµ·æ¥åº”è¯¥æ˜¯è¿™æ ·çš„ï¼š
[0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1]
ä»–è¡¨ç¤ºå‰8è¡Œå±äº0ç±»ï¼Œä¹Ÿå°±æ˜¯longç±»ï¼›å8è¡Œå±äº1ç±»ï¼Œä¹Ÿå°±æ˜¯shortç±»ã€‚
åœ¨æˆ‘ä»¬çš„ç¨‹åºä¸­æ˜¯é€šè¿‡ä¸‹é¢çš„ç¨‹åºæ®µè¾¾åˆ°è¿™æ ·çš„æ•ˆæœã€‚


```py
test_output_tensor = torch.tensor([int(y == 1.0) for x, y in outputs])
```
è¿™é‡Œå·§å¦™åœ°åº”ç”¨äº†å°†boolæ•°æ®è½¬æ¢æˆæ•´æ•°çš„æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯int(True)ä¸º1ï¼Œint(Fale)ä¸º0.è¿˜è¦æ³¨æ„åˆ°æˆ‘ä»¬çš„longå’Œshortæ˜¯ç›¸å…³çš„ï¼Œx=1åˆ™y=0,åä¹‹äº¦ç„¶ã€‚æ‰€ä»¥ç¨‹åºä¸­åªä½¿ç”¨äº†yçš„å€¼ï¼Œå°±å¾—åˆ°äº†æ­£ç¡®çš„æµ‹è¯•è¾“å‡ºæ•°ç»„ã€‚

ğŸ‘ğŸ˜„ **Conclusion**
è¿è¡Œ
* [read stock data, build model, save model to a fileï¼Œstock.py](../src/stock.py)
![most time only get 50% accuracy](images/50percent.png)
![occasionally get 83% accuracy](images/83%.png)

```py input data
file_path = 'stockdata/SPY_TraningData_30_07.csv'
```

âŒğŸ˜¢<font style="background-color:yellow">ä»…ä»…å¾—åˆ°50%çš„ç²¾å‡†åº¦ï¼Œè¡¨æ˜è¿™æ ·çš„æ•°æ®ç»“æ„å’ŒNNæ¨¡å‹æ˜¯å®Œå…¨ä¸èƒ½å¤Ÿé¢„æµ‹è‚¡ç¥¨èµ°åŠ¿çš„ã€‚</font>

[use model file to predict stock data(which is same as the trainging data)](../src/stock1.py)

![](images/StockTrainModel.png)

```
tensor([[1., 0.,0],
        [1., 0.,0],
        [1., 0.,0],
        [0., 0.,1],
        [0.,1,0.],
        ...
        [0., 1.]])
```
* [load model from file built by stock.py, use the model to test](../src/stock1.py)

```py input data
file_path = 'stockdata/SPY_TraningData_30_07.csv'
```

![occasionally get 83% accuracy,stock_model_30_07_83.pth](images/83%.png)

```text
(env) C:\Users\wangq\workspace\LearnTorch>c:/Users/wangq/workspace/LearnTorch/env/Scripts/python.exe c:/Users/wangq/workspace/LearnTorch/src/stock1.py
18
18 180
window: 30
Predicted: "long", Actual: "long"
Predicted: "long", Actual: "long"
Predicted: "long", Actual: "long"
Predicted: "long", Actual: "long"
Predicted: "long", Actual: "long"
Predicted: "long", Actual: "long"
Predicted: "short", Actual: "long"
Predicted: "long", Actual: "long"
Predicted: "short", Actual: "long"
Predicted: "short", Actual: "short"
Predicted: "short", Actual: "short"
Predicted: "short", Actual: "short"
Predicted: "short", Actual: "short"
Predicted: "short", Actual: "short"
Predicted: "short", Actual: "short"
Predicted: "short", Actual: "short"
Predicted: "short", Actual: "short"
Predicted: "long", Actual: "short"
accuracy: 83.33
```

ğŸ‘ğŸ˜„ ä»¤äººå¯å–œçš„ç»“è®ºï¼š
> ä¸€æ—¦æ¨¡å‹ä¿å­˜åœ¨æ–‡ä»¶ä¸­ï¼Œé‡å¤ä½¿ç”¨çš„ç²¾åº¦æ˜¯ä¸€ç›´ä¿æŒç€çš„ã€‚

ğŸ‘ğŸ˜¢ å¯æ‚²çš„æ˜¯ï¼š
> è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®å®Œå…¨ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œç²¾åº¦åº”è¯¥æ˜¯100%æ‰å¯¹ã€‚â€œé¢„æµ‹åç¦»â€
> 1. window=30 å¤ªå°
> 2. åªæœ‰18ä¸ªç‚¹ï¼Œè®­ç»ƒæ•°æ®å¤ªå°‘ã€‚
> 3. çº¿æ€§æ¨¡å‹ä¸å¤Ÿå¥½ï¼Ÿ

ğŸ””âš¡ï¸ <font style="background-color:yellow">å¶ç„¶å‘ç°çš„buyçš„æµ‹è¯•æ¯”sellçš„æµ‹è¯•æ›´ç²¾ç¡®çš„ç°è±¡æ˜¯ä¸å­˜åœ¨çš„ã€‚æ ¹æ®ç›®å‰çš„ç»“æœï¼Œä¸¤è€…æ²¡æœ‰å·®å¼‚ã€‚</font>

* [plot one window data with Velocity or Accelaration, stock2.py](../src/stock2.py)
![](images/buyPoint_15.png)
* [read training and testing data separately, stock4.py](../src/stock4.py)

## Add Weights on Data

* [add linear weights on Data, stock5.py](../src/stock5.py)

å¦‚æœè®­ç»ƒæ•°æ®ä¸åŒ…æ‹¬æµ‹è¯•æ•°æ®ï¼ˆstockdata/SPY_TrainingData_200_09.csv, 53pointsï¼‰ï¼Œç²¾åº¦è¾ƒä½ï¼Œæœ€é«˜åªè¾¾åˆ°84%ã€‚

å¦‚æœè®­ç»ƒæ•°æ®åŒ…æ‹¬æµ‹è¯•æ•°æ®ï¼ˆstockdata/SPY_TrainingData_200_10.csv, 65pointsï¼‰ï¼Œç²¾åº¦è¾ƒé«˜ï¼Œæœ€é«˜å¯è¾¾åˆ°100%ã€‚65pointsä¸­æœ‰13ä¸ªç”¨æ¥ä½œä¸ºæµ‹è¯•æ•°æ®ã€‚

```text çº¿æ€§åŠ æƒ
Epoch 19********************
loss: 3.667773  [    5/   65]
loss: 0.000000  [   30/   65]
loss: 0.000000  [   55/   65]
Test Error:
 Accuracy: 100.0%, Avg loss: 0.000000

Epoch 20********************
loss: 3.534004  [    5/   65]
loss: 0.000000  [   30/   65]
loss: 0.000000  [   55/   65]
Test Error:
 Accuracy: 100.0%, Avg loss: 0.000000

Done with training.
Saved PyTorch Model State to stock_model_200_10_100_linearWeighted.pth
```

* [add exponential weights on Data and normalization](../src/stock6.py)
1. åŸå§‹ä»·æ ¼ï¼Œæœ€å¥½ç²¾åº¦=92%
2. åªå½’ä¸€ï¼Œæœ€å¥½ç²¾åº¦=66%
3. å½’ä¸€åŠ æŒ‡æ•°æƒé‡ï¼Œæœ€å¥½ç²¾åº¦=60%

ğŸ‘ğŸ˜„ **Conclusion**

> æ„Ÿè§‰ä½¿ç”¨åŸå§‹æ•°æ®æ‰€åšçš„æ¨¡å‹ç²¾åº¦ï¼Œè¿œå¥½äºå½’ä¸€åŒ–åçš„æ•°æ®ã€‚â€œé¢„æµ‹åç¦»â€
> åŠ æƒåå¹¶æ²¡æœ‰æ”¹è¿›ç²¾åº¦ã€‚
> å› ä¸ºæˆ‘ä»¬å¹¶æ²¡æœ‰ä¸å…¶ä»–æ•°æ®ä½œæ¯”å¯¹ï¼Œæ‰€ä»¥å½’ä¸€åŒ–åº”è¯¥æ²¡æœ‰ä»»ä½•å½±å“æ‰å¯¹ã€‚ğŸ˜¢ğŸ˜¢

* [comparison of linear and exponential weights](../src/stock7.py)
![](images/weights.png)

## Add hold as output as [long, hold, short]

![](images/StockTrainModel-2.png)

ğŸ’¡ğŸ‘‰ Idea of selecting hold points
1. between long and short, evenly select 3 or 5 points as hold points.

* [add hold to classify long and short](../src/stock8.py)
* [training data with row=196, window=50, column=6](../stockdata/SPY_TrainingData_50_13.csv)
* [testing data with row=196, window=50, column=6](../stockdata/SPY_TestingData_50_13.csv)

```
Epoch 20********************
loss: 1.341251  [    4/  196]
loss: 1.352880  [   20/  196]
loss: 1.736566  [   36/  196]
loss: 1.582978  [   52/  196]
loss: 0.872862  [   68/  196]
loss: 0.565427  [   84/  196]
loss: 0.624644  [  100/  196]
loss: 0.593255  [  116/  196]
loss: 0.521536  [  132/  196]
loss: 0.528101  [  148/  196]
loss: 0.471056  [  164/  196]
loss: 0.508025  [  180/  196]
loss: 0.434915  [  196/  196]
Test Error:
 Accuracy: 67.4%, Avg loss: 0.844671

Done with training.
Saved PyTorch Model State to best_stock_model_69.pth
```
ä¿®æ”¹äº†ç¨‹åºï¼ŒæŠŠæœ€é«˜ç²¾åº¦çš„æ¨¡å‹ä¿å­˜åœ¨æ–‡ä»¶ä¸­ã€‚

ç¬¬13å¥—æ•°æ®åªè·å¾—æœ€é«˜69%çš„ç²¾åº¦ã€‚

## Available Models

![](images/possibleModels.png)

### å·ç§¯ç¥ç»ç½‘ç»œ
[](ConvolutionalNeuralNetworks.md)
[ææ°¸ä¹è€å¸ˆè®²å·ç§¯](https://www.youtube.com/watch?v=AFlIM0jSI9I)
* [å·ç§¯ç¥ç»ç½‘ç»œdoes NOT work](../src/cnn.py)
* [å·ç§¯ç¥ç»ç½‘ç»œworks from ChatGPT directly](../src/cnn1.py)
* [å·ç§¯ç¥ç»ç½‘ç»œwith data SPY_TrainingData_200_10.csv works](../src/stock_cnn_wang.py)

get 93% accuracy easily.

### Recurrent Neural Network

* [Recurrent Neural Network from ChatGPT](../src/rnn.py)
* [Recurrent with data SPY_TrainingData_200_10.csv works](../src/stock_rnn_wang.py)
the accura 67.7%.

### Attension Machanics

* [Attension Machanics model from ChatGPT](../src/attention.py)
* [Use attensio Machinics model train stock data](../src/stock_attension_wang.py)
Accuracy: 60.0%, Avg loss: 0.690121

### Transform æ¨¡å‹

* [Trasform model class from ChatGPT](../src/transform.py)
* [Use Transform model train stock data](../src/stock_transform_wang.py)
 Accuracy: 100.0%, Avg loss: 0.002986

### AutoEncoders

* [](../src/autoencoder.py)
* [Auto Encode model from ChatGPT](../src/autoencoder2.py)
* [Use Auto Encode model train stock data](../src/stock_autoencode_wang.py)
Accuracy: 100.0%, Avg loss: 0.000001

### ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ
Generative Adversarial Network (GAN)

* [understand what it is](../src/gan.py)
* [Successful](../src/gan1.py)

### Reinforcement Learning

* [Need use real data](../src/reinforcement.py)

## AIæ— æ³•å­¦ä¹ çš„æ•°æ®å½¢æ€

ğŸ˜¢ğŸ“Œä¸€æ—¦æ•°æ®é‡å¢å¤§ï¼Œå‡ ä¹æ‰€æœ‰çš„æ¨¡å‹éƒ½åªèƒ½å¾—åˆ°50%çš„ç²¾åº¦ï¼Œç”šè‡³æ›´ä½ã€‚

* [å·ç§¯æ¨¡å‹ï¼Œ2328ä¹°å–ç‚¹ï¼Œçª—å£30ï¼Œåªå¾—åˆ°50%](../src/stock_cnn_wang_150.py)
* [å·ç§¯æ¨¡å‹ï¼Œ2328ä¹°å–ç‚¹ï¼Œåªå¾—åˆ°50%](../src/stock_cnn_wang_151.py)
* [å·ç§¯æ¨¡å‹ï¼Œ2328ä¹°å–ç‚¹ï¼Œåªå¾—åˆ°50%](../src/stock_cnn_wang_152.py)
* [Transformï¼Œ2328ä¹°å–ç‚¹ï¼Œçª—å£60ï¼Œåªå¾—åˆ°50%](../src/stock_transform_wang_151.py)
* [åªå–ä¸€åˆ—ä»·æ ¼æ•°æ®ï¼Œå›ºå®šçª—å£ä¸º30ä¸ªç‚¹ï¼Œåªå¾—åˆ°50%](../src/stock_160.py)

```dos
Epoch 20********************
loss: 0.868377  [   64/ 9066]
loss: 0.867910  [ 4160/ 9066]
loss: 0.542266  [ 8256/ 9066]
Test Error: 
 Accuracy: 50.0%, Avg loss: 0.704931
```
## å¯å˜é•¿çš„æ—¶é—´åºåˆ—

> æŒ‰ç…§æ•°æ®å˜åŒ–æ ·å¼å–è®­ç»ƒæ•°æ®ï¼ŒæŒ‰ç…§æœ€é•¿çš„æ—¶é—´åºåˆ—ï¼Œå°†çŸ­çš„æ—¶é—´åºåˆ—ç”¨0è¡¥è¶³ã€‚

â“ğŸ˜¢è¿™æ ·åšï¼Œå¯èƒ½å¯¹è®­ç»ƒå’Œæµ‹è¯•è§£å†³â€œæ²¡æœ‰å¯å­¦ä¹ çš„æ•°æ®å½¢æ€â€çš„é—®é¢˜ï¼Œä½†æ˜¯å¦‚ä½•åœ¨é¢„æµ‹ä¸­æ„é€ ä½ çš„è¾“å…¥æ•°æ®å‘¢ï¼Ÿéš¾åœ¨é¢„æµ‹æ—¶ï¼Œå¦‚ä½•ç¡®å®šè¾“å…¥æ•°æ®çš„é•¿åº¦å‘¢ï¼Ÿ

ğŸ’¡ğŸ‘‰Deep Learning crucial points

1. The training data must be learnable.
2. The test data should contain patterns similar to those in the training data.
3. The input data for predictions should have patterns similar to the trained input data.

* [Time Series Transformer model](../src/Test_TimeSeriesTransformer_03.py)
[Time Series Data](../data/SPX_TrainingData_200.csv)
[quick plot tool](../src/plotTools.py)

![row 5710 has 13 points](images/data5710_13.png)
show the buy/sell pair dataset. it definitely has from low to hight pattern, but cannot be used in prediction.

![](images/data_10_245.png)
since the time series difference, the row 5710 has only 13 points data, and row 10 has 245 points, huge difference. question is how to pad the data to keep the same learnable pattern?

ğŸ‘ğŸ˜± all different length dataset, has similer pattern, which is from low to high, or vice versa. computer will learn nothing but this simple pattern!

```debug
padded_sequences[2,:]
tensor([1.0000, 0.7732, 0.9991, 0.8992, 0.7307, 0.7309, 0.5683, 0.7300, 0.2079,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
```

![](images/paddedSequences.png)

```
mask[1,:]
tensor([False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False

len(mask[1,:])
357        
```

```py
for epoch in range(num_epochs):
    epoch_start_time = time.time()
    epoch_loss = 0.0
    print(f"Starting epoch {epoch+1}/{num_epochs}...")
    for (low_batch, low_mask), (high_batch, high_mask) in zip(low_dataloader, high_dataloader):
        for batch, mask in [(low_batch, low_mask), (high_batch, high_mask)]:
            batch = batch.unsqueeze(-1)  # Adding feature dimension
            tgt_input = batch[:, :-1, :]
            tgt_output = batch[:, 1:, :]

            tgt_subsequent_mask = create_subsequent_mask(tgt_input.size(1)).to(tgt_input.device)

            optimizer.zero_grad()
ğŸ’¡ğŸ‘‰       output = model(
                batch, tgt_input, tgt_mask=tgt_subsequent_mask, 
                src_key_padding_mask=mask, tgt_key_padding_mask=mask[:, :-1]
            )
            print(f"Model output shape: {output.shape}")
```

tgt_output.shape
torch.Size([32, 82, 1])

tgt_intput: target input
tgt_input.shape
torch.Size([32, 82, 1])
å…±æœ‰32å¥—æ•°æ®ï¼Œæ¯å¥—æœ‰82ä¸ªä»·æ ¼ï¼Œå•ä¸€ä»·æ ¼æè¿°è‚¡ç¥¨å±æ€§ã€‚å…³é”®æ˜¯å¤§éƒ¨åˆ†çš„æ•°æ®æ˜¯åç¼€è¡¥0.

batch.shape
torch.Size([32, 83, 1])

tgt_subsequent_mask.shape
torch.Size([82, 82])

tgt_subsequent_mask
tensor([[False,  True,  True,  ...,  True,  True,  True],
        [False, False,  True,  ...,  True,  True,  True],
        [False, False, False,  ...,  True,  True,  True],
        ...,
        [False, False, False,  ..., False,  True,  True],
        [False, False, False,  ..., False, False,  True],
        [False, False, False,  ..., False, False, False]])

mask.shape
torch.Size([32, 83])

mask
tensor([[False, False, False,  ...,  True,  True,  True],
        [False, False, False,  ...,  True,  True,  True],
        [False, False, False,  ...,  True,  True,  True],
        ...,
        [False, False, False,  ...,  True,  True,  True],
        [False, False, False,  ...,  True,  True,  True],
        [False, False, False,  ...,  True,  True,  True]])

output.shape
torch.Size([32, 82, 1])

output.shape
torch.Size([2624, 1])

tgt_output.shape
torch.Size([2624, 1])

output
tensor([[ 0.3952],
        [ 0.1312],
        [ 0.5834],
        ...,
        [ 0.3008],
        [ 0.4594],
        [-0.0273]], grad_fn=<ViewBackward0>)

tgt_output
tensor([[0.6721],
        [0.5523],
        [0.6548],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]])


## GRU model

## Load Stock Data to sqlite database
* [Download stock data from internet and save it into CSV file]()
* [read CSV file and save to Sqlite database](../src/WriteCsvToSql.py)
* [](../src/ConcatCSVFiles.py)

### Generate Training & Testing Data
![Demo how to generate forcast training data](images/StockForecast.png)
[åˆ‡ç‰‡ç”Ÿæˆè®­ç»ƒã€æµ‹è¯•ã€é¢„æµ‹æ•°æ®](../src/GenTrainTestDataBig_fixlen_GRU_2.py)

### Create a GRU model
* [Generate GRU model and save to a file](../src/Test_GRUX3_fixlen_01.py)

ğŸ””âš¡ï¸Experience
1. epoch: when loss does NOT go down, epoch size is enough.
2. Learning Rate: when loss changes back and forth, LR is too big; when loss changes too small, LR is too small.
3. no matter how to change LR, and epoch, the final loss almost fixed, means you are reach the best loss.

### Forcast Future Stock Price Range
* [forecast future stock normalized price range](../src/Test_GRUX3_fixlen_01_predict.py)

```
1. Load test data.
2. Create dataloader.
3. Load the saved model.
4. Evaluate the model on test data.
--------------- Test Results ---------------
Test Loss (MSE): 0.01390344
Mean Absolute Error (MAE): 0.07444746
R-squared (R2): 0.89404035
---------------------------------------------
1. Predict feture values.
Data shape: (10, 120, 5)
Targets shape: (10, 3)
----------------------------------------------------------------
Prediction for sequence 0: [0.17550081 0.18547772 0.19838372]
Real  data for sequence 0: [0.1769437  0.17068811 0.16907954]
----------------------------------------------------------------
Prediction for sequence 1: [0.91071075 0.9159886  0.9081013 ]
Real  data for sequence 1: [0.82054598 0.89281609 0.85747126]
----------------------------------------------------------------
Prediction for sequence 2: [0.90285707 0.90407133 0.88744545]
Real  data for sequence 2: [0.88318741 0.8823562  0.88252244]
----------------------------------------------------------------
Prediction for sequence 3: [0.94254965 0.935987   0.94824004]
Real  data for sequence 3: [0.96575879 1.         0.97637487]
----------------------------------------------------------------
Prediction for sequence 4: [0.25471193 0.2625934  0.29117215]
Real  data for sequence 4: [0.27425204 0.32887579 0.32524932]
----------------------------------------------------------------
Prediction for sequence 5: [0.9175505  0.91640943 0.8980696 ]
Real  data for sequence 5: [1.         0.98027574 0.9993962 ]
----------------------------------------------------------------
Prediction for sequence 6: [0.08631686 0.09392065 0.08612403]
Real  data for sequence 6: [0.13514782 0.19099015 0.36884092]
----------------------------------------------------------------
Prediction for sequence 7: [0.23528987 0.23136936 0.24292988]
Real  data for sequence 7: [0.06003752 0.12757974 0.17518762]
----------------------------------------------------------------
Prediction for sequence 8: [0.15681821 0.15669872 0.17343152]
Real  data for sequence 8: [0.06746301 0.06664857 0.        ]
----------------------------------------------------------------
Prediction for sequence 9: [0.95848805 0.94515836 0.9446089 ]
Real  data for sequence 9: [0.91780397 0.92152605 0.8560794 ]
```

## Activate Functions
