<h1>Convolutional Neural Networks (CNNs)</h1>

* [ä»â€œå·ç§¯â€ã€åˆ°â€œå›¾åƒå·ç§¯æ“ä½œâ€ã€å†åˆ°â€œå·ç§¯ç¥ç»ç½‘ç»œâ€ï¼Œâ€œå·ç§¯â€æ„ä¹‰çš„3æ¬¡æ”¹å˜](https://www.youtube.com/watch?v=D641Ucd_xuw)
* [](https://www.youtube.com/watch?v=JJSkAkPS8x4)
  
* [äººè„¸è¯†åˆ«å•¥åŸç†ï¼Ÿäººå·¥æ™ºèƒ½ï¼ˆäºŒï¼‰å·ç§¯ç¥ç»ç½‘ç»œ, ææ°¸ä¹è€å¸ˆ](https://www.youtube.com/watch?v=AFlIM0jSI9I)

* [æœºå™¨èƒ½åƒäººä¸€æ ·æ€è€ƒå—ï¼Ÿäººå·¥æ™ºèƒ½ï¼ˆä¸€ï¼‰æœºå™¨å­¦ä¹ å’Œç¥ç»ç½‘ç»œ](https://www.youtube.com/watch?v=5A9bmW1qTpk)

Convolutional Neural Networks (CNNs) are a class of deep learning algorithms specifically designed for processing and analyzing data with a grid-like topology, such as images. CNNs have achieved state-of-the-art performance in various computer vision tasks, including image classification, object detection, and image segmentation. Hereâ€™s an overview of the key components and concepts of CNNs:

### Key Components of CNNs

1. **Convolutional Layer**
   - **Purpose**: Extract features from the input data.
   - **Operation**: Applies a set of filters (kernels) to the input data. Each filter slides over the input data (convolution operation), producing a feature map.
   - **Output**: Feature maps that highlight different aspects of the input data (e.g., edges, textures).

2. **Pooling Layer**
   - **Purpose**: Reduce the spatial dimensions of the feature maps, thus decreasing the computational load and helping to control overfitting.
   - **Types**: 
     - **Max Pooling**: Takes the maximum value in each patch of the feature map.
     - **Average Pooling**: Takes the average value in each patch of the feature map.
   - **Operation**: Slides a window over the input feature map and reduces its dimensions.

3. **Activation Function**
   - **Purpose**: Introduce non-linearity into the model, allowing it to learn complex patterns.
   - **Common Functions**: ReLU (Rectified Linear Unit), Sigmoid, Tanh.
   - **ReLU**: Most widely used, helps mitigate the vanishing gradient problem by outputting zero for negative values and the same value for positive ones.

4. **Fully Connected (Dense) Layer**
   - **Purpose**: Combine features learned by convolutional and pooling layers to make predictions.
   - **Operation**: Each neuron in a fully connected layer is connected to every neuron in the previous layer.
   - **Output**: Typically the final classification output or regression result.

### CNN Architecture

A typical CNN architecture consists of alternating convolutional and pooling layers, followed by one or more fully connected layers. Hereâ€™s a simplified architecture:

1. **Input Layer**: Takes the raw input data (e.g., an image).
2. **Convolutional Layer(s)**: Apply multiple filters to extract various features from the input.
3. **Pooling Layer(s)**: Reduce the dimensions of the feature maps.
4. **Fully Connected Layer(s)**: Process the extracted features to produce the final output.

### Example: Simple CNN with PyTorch

Hereâ€™s an example of a simple CNN implementation using PyTorch:

[Create a model, and save to file](../src/simpleCNN.py)
[load model from the file, and test the model](../src/simpleCNN1.py)
[load model from the file, and test the model](../src/simpleCNN2.py)
[find best learning rate](../src/simpleCNN4.py)

This code defines a simple CNN with two convolutional layers, two pooling layers, and three fully connected layers. It uses the CIFAR-10 dataset for training, applying standard data transformations. The model is trained for two epochs, printing the training loss every 2000 mini-batches.

å·ç§¯æ ¸ï¼ˆä¹Ÿç§°ä¸ºæ»¤æ³¢å™¨æˆ–æƒé‡ï¼‰æ˜¯å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ã€‚å®ƒä»¬åœ¨å›¾åƒå¤„ç†ä¸­ç”¨äºæå–ç‰¹å¾ã€‚æ¯ä¸ªå·ç§¯å±‚åŒ…å«å¤šä¸ªå·ç§¯æ ¸ï¼Œè¿™äº›å·ç§¯æ ¸åœ¨è¾“å…¥å›¾åƒä¸Šæ»‘åŠ¨ï¼Œé€šè¿‡å·ç§¯æ“ä½œç”Ÿæˆç‰¹å¾å›¾ã€‚

### ä¸»è¦æ¦‚å¿µ

1. **å·ç§¯æ ¸**ï¼šæ˜¯ä¸€ä¸ªå°çŸ©é˜µï¼ˆé€šå¸¸æ˜¯3x3, 5x5ç­‰ï¼‰ï¼Œå®ƒåœ¨è¾“å…¥å›¾åƒä¸Šæ»‘åŠ¨ï¼Œæ‰§è¡Œå·ç§¯æ“ä½œã€‚è¿™äº›æ ¸å­¦ä¹ åˆ°å›¾åƒä¸­çš„ä¸åŒç‰¹å¾ï¼Œæ¯”å¦‚è¾¹ç¼˜ã€çº¹ç†ç­‰ã€‚
  
2. **å·ç§¯æ“ä½œ**ï¼šå·ç§¯æ ¸åœ¨è¾“å…¥å›¾åƒä¸Šæ»‘åŠ¨ï¼Œæ¯æ¬¡è®¡ç®—ä¸€ä¸ªå±€éƒ¨åŒºåŸŸçš„ç‚¹ç§¯ã€‚å·ç§¯æ“ä½œçš„ç»“æœæ˜¯ä¸€ä¸ªç‰¹å¾å›¾ã€‚

3. **ç‰¹å¾å›¾**ï¼šå·ç§¯æ“ä½œç”Ÿæˆçš„è¾“å‡ºå›¾åƒï¼Œåæ˜ äº†å·ç§¯æ ¸åœ¨è¾“å…¥å›¾åƒä¸­æ£€æµ‹åˆ°çš„ç‰¹å¾ã€‚

4. **æ± åŒ–å±‚**ï¼šé€šå¸¸è·Ÿåœ¨å·ç§¯å±‚åé¢ï¼Œç”¨äºå‡å°‘ç‰¹å¾å›¾çš„ç»´åº¦ï¼Œä»è€Œå‡å°‘è®¡ç®—é‡å¹¶é˜²æ­¢è¿‡æ‹Ÿåˆã€‚å¸¸è§çš„æ± åŒ–æ“ä½œæœ‰æœ€å¤§æ± åŒ–å’Œå¹³å‡æ± åŒ–ã€‚

### å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„å·ç§¯æ“ä½œ

ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„å·ç§¯æ“ä½œç¤ºä¾‹ï¼š

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

# å®šä¹‰ä¸€ä¸ªç®€å•çš„CNNæ¨¡å‹
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)  # 3è¾“å…¥é€šé“ï¼ˆRGBï¼‰ï¼Œ6è¾“å‡ºé€šé“ï¼Œ5x5å·ç§¯æ ¸
        self.pool = nn.MaxPool2d(2, 2)   # 2x2æ± åŒ–
        self.conv2 = nn.Conv2d(6, 16, 5) # 6è¾“å…¥é€šé“ï¼Œ16è¾“å‡ºé€šé“ï¼Œ5x5å·ç§¯æ ¸
        self.fc1 = nn.Linear(16 * 5 * 5, 120) # å…¨è¿æ¥å±‚
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x))) # åº”ç”¨conv1, ReLUå’Œpool
        x = self.pool(F.relu(self.conv2(x))) # åº”ç”¨conv2, ReLUå’Œpool
        x = x.view(-1, 16 * 5 * 5) # å±•å¹³å¼ é‡
        x = F.relu(self.fc1(x))    # åº”ç”¨å…¨è¿æ¥å±‚å’ŒReLU
        x = F.relu(self.fc2(x))
        x = self.fc3(x)            # è¾“å‡ºå±‚
        return x

# åˆå§‹åŒ–æ¨¡å‹
net = SimpleCNN()
print(net)
```

### æé«˜æ¨¡å‹æ€§èƒ½çš„å·ç§¯æ“ä½œ

ä½ å¯ä»¥é€šè¿‡æ”¹å˜å·ç§¯æ ¸çš„å¤§å°ã€æ•°é‡å’Œå±‚æ•°æ¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¸¸è§çš„ç­–ç•¥ï¼š

1. **å¢åŠ å·ç§¯å±‚çš„æ•°é‡**ï¼šå¢åŠ æ›´å¤šçš„å·ç§¯å±‚å¯ä»¥æ•è·æ›´å¤æ‚çš„ç‰¹å¾ã€‚

2. **å¢åŠ å·ç§¯æ ¸çš„æ•°é‡**ï¼šæ¯å±‚æ›´å¤šçš„å·ç§¯æ ¸å¯ä»¥æå–æ›´å¤šçš„ç‰¹å¾ã€‚

3. **è°ƒæ•´å·ç§¯æ ¸çš„å¤§å°**ï¼šæ›´å°çš„å·ç§¯æ ¸ï¼ˆä¾‹å¦‚3x3ï¼‰é€šå¸¸æ•ˆæœæ›´å¥½ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥æ•è·æ›´ç»†å¾®çš„ç‰¹å¾ã€‚

4. **ä½¿ç”¨ä¸åŒçš„æ¿€æ´»å‡½æ•°**ï¼šReLUæ˜¯æœ€å¸¸ç”¨çš„ï¼Œä½†ä¹Ÿå¯ä»¥å°è¯•å…¶ä»–æ¿€æ´»å‡½æ•°ï¼Œå¦‚Leaky ReLUæˆ–ELUã€‚

5. **æ‰¹é‡å½’ä¸€åŒ–**ï¼šåœ¨æ¯ä¸ªå·ç§¯å±‚ä¹‹åæ·»åŠ æ‰¹é‡å½’ä¸€åŒ–å¯ä»¥åŠ é€Ÿè®­ç»ƒå¹¶ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªæ”¹è¿›çš„CNNæ¨¡å‹ç¤ºä¾‹ï¼š

```python
class ImprovedCNN(nn.Module):
    def __init__(self):
        super(ImprovedCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # 3è¾“å…¥é€šé“ï¼Œ32è¾“å‡ºé€šé“ï¼Œ3x3å·ç§¯æ ¸ï¼Œpadding=1
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)
        self.fc1 = nn.Linear(128 * 4 * 4, 512)  # è°ƒæ•´äº†æ± åŒ–å±‚åçš„å°ºå¯¸
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 10)
        self.dropout = nn.Dropout(0.5)
        self.batch_norm1 = nn.BatchNorm2d(32)
        self.batch_norm2 = nn.BatchNorm2d(64)
        self.batch_norm3 = nn.BatchNorm2d(128)
        self.batch_norm4 = nn.BatchNorm2d(128)

    def forward(self, x):
        x = self.pool(F.relu(self.batch_norm1(self.conv1(x)))) 
        x = self.pool(F.relu(self.batch_norm2(self.conv2(x))))
        x = self.pool(F.relu(self.batch_norm3(self.conv3(x))))
        x = self.pool(F.relu(self.batch_norm4(self.conv4(x))))
        x = x.view(-1, 128 * 4 * 4)  # è°ƒæ•´å±•å¹³å°ºå¯¸
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

# åˆå§‹åŒ–æ”¹è¿›åçš„æ¨¡å‹
net = ImprovedCNN()
print(net)
```

é€šè¿‡è¿™äº›æ”¹è¿›ï¼Œä½ åº”è¯¥èƒ½å¤Ÿæé«˜æ¨¡å‹åœ¨CIFAR-10æ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚å¦‚æœä½ é‡åˆ°å…¶ä»–é—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥çš„ä¼˜åŒ–å»ºè®®ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼

[show original, identity, edge, sharpen](../src/imageConverlotion.py)

The sharpening convolution kernel you provided is a 3x3 matrix:

```
[[ 0, -1,  0],
 [-1,  5, -1],
 [ 0, -1,  0]]
```

This kernel is used in image processing to enhance the edges and details in an image, making it appear sharper. Here's how the kernel works:

1. **Center Pixel Weight**: The center pixel of the kernel (5 in this case) has a higher weight, which means it contributes more to the resulting pixel value. This weight emphasizes the importance of the center pixel in the sharpening process.

2. **Neighboring Pixel Weights**: The surrounding pixels (top, bottom, left, right) have a weight of -1. These weights are negative because they are used to subtract the surrounding pixel values from the center pixel value. This subtraction creates a higher contrast between the center pixel and its neighbors, enhancing edges.

3. **Zero Weights**: The pixels in the corners of the kernel have a weight of 0, which means they are not used in the sharpening process. This is because corner pixels do not have direct neighboring pixels in the 3x3 kernel.

When this kernel is applied to an image using convolution, it calculates a new value for each pixel in the image based on the weighted sum of the pixel values in the neighborhood defined by the kernel. The result is a sharpened image with enhanced edges and details.

The convolution of two sequences \( f \) and \( g \) can be calculated using the following formula:

\[ (f * g)[n] = \sum_{k=0}^{n} f[k] \cdot g[n-k] \]

where \( n \) ranges from 0 to \( (N + M - 2) \), with \( N \) and \( M \) being the lengths of \( f \) and \( g \), respectively. 

Let's calculate the convolution of \( f = [1, 2, 3] \) and \( g = [0, 1, 0.5] \):

1. Pad the sequences \( f \) and \( g \) with zeros to make the length \( N + M - 1 = 3 + 3 - 1 = 5 \):
   - \( f = [1, 2, 3, 0, 0] \)
   - \( g = [0, 1, 0.5, 0, 0] \)

2. Calculate the convolution for each \( n \) from 0 to 4.

Let's go through the calculations step by step:

- For \( n = 0 \):
  \[ (f * g)[0] = 1 \cdot 0 = 0 \]

- For \( n = 1 \):
  \[ (f * g)[1] = 1 \cdot 1 + 2 \cdot 0 = 1 \]

- For \( n = 2 \):
  \[ (f * g)[2] = 1 \cdot 0.5 + 2 \cdot 1 + 3 \cdot 0 = 0.5 + 2 = 2.5 \]

- For \( n = 3 \):
  \[ (f * g)[3] = 2 \cdot 0.5 + 3 \cdot 1 = 1 + 3 = 4 \]

- For \( n = 4 \):
  \[ (f * g)[4] = 3 \cdot 0.5 = 1.5 \]

Putting it all together, the convolution of \( f \) and \( g \) is:

\[ f * g = [0, 1, 2.5, 4, 1.5] \]

[](../src/convolution2.py)

ğŸ‘ğŸ˜±ä¸‹é¢æ˜¯ChatGPTç»™å‡ºçš„ç­”æ¡ˆä¹‹ä¸€ï¼Œé”™å¾—ç¦»è°±ã€‚

å·ç§¯ï¼ˆConvolutionï¼‰æ˜¯æ•°å­¦ä¸­ä¸€ç§é‡è¦çš„è¿ç®—ï¼Œå¹¿æ³›åº”ç”¨äºä¿¡å·å¤„ç†ã€å›¾åƒå¤„ç†ã€ç»Ÿè®¡å­¦ã€ä»¥åŠæ·±åº¦å­¦ä¹ ç­‰é¢†åŸŸã€‚å°½ç®¡å®ƒçš„æ¦‚å¿µæœ‰äº›æŠ½è±¡ï¼Œä½†ç†è§£å…¶åŸºæœ¬åŸç†æœ‰åŠ©äºæ›´å¥½åœ°åº”ç”¨å’Œåˆ†ææ•°æ®ã€‚

### å·ç§¯çš„å®šä¹‰

åœ¨æ•°å­¦ä¸Šï¼Œå·ç§¯æ˜¯ä¸¤ä¸ªå‡½æ•° \( f \) å’Œ \( g \) çš„ä¸€ç§æ“ä½œï¼Œå…¶ç»“æœæ˜¯ä¸€ä¸ªæ–°å‡½æ•°ã€‚å¯¹äºè¿ç»­å‡½æ•° \( f(t) \) å’Œ \( g(t) \)ï¼Œå·ç§¯å®šä¹‰ä¸ºï¼š

\[ (f * g)(t) = \int_{-\infty}^{\infty} f(\tau)g(t - \tau) \, d\tau \]

å¯¹äºç¦»æ•£å‡½æ•° \( f[n] \) å’Œ \( g[n] \)ï¼Œå·ç§¯å®šä¹‰ä¸ºï¼š

\[ (f * g)[n] = \sum_{m=-\infty}^{\infty} f[m]g[n - m] \]

å…¶ä¸­ï¼Œç¬¦å· â€œ*â€ è¡¨ç¤ºå·ç§¯è¿ç®—ã€‚

### å·ç§¯çš„ç›´è§‚ç†è§£

ğŸ‘ğŸ˜± é”™å¾—ç¦»è°±ï¼šå·ç§¯å¯ä»¥ç†è§£ä¸ºå¯¹å‡½æ•°è¿›è¡Œâ€œæ»‘åŠ¨å¹³å‡â€ã€‚ä»¥ç¦»æ•£æƒ…å†µä¸‹çš„å·ç§¯ä¸ºä¾‹ï¼š

1. å°†å‡½æ•° \( g \) ç¿»è½¬å¹¶å¹³ç§»ã€‚
2. è®¡ç®—ç¿»è½¬å \( g \) ä¸ \( f \) åœ¨æ¯ä¸ªä½ç½®çš„é‡å éƒ¨åˆ†çš„ä¹˜ç§¯ä¹‹å’Œã€‚
3. å°†è¿™äº›å’Œå€¼ä½œä¸ºæ–°å‡½æ•°çš„å€¼ã€‚

### ä¸¾ä¾‹è¯´æ˜

å‡è®¾ä¸¤ä¸ªåºåˆ—åˆ†åˆ«æ˜¯ï¼š

\[ f = [1, 2, 3] \]
\[ g = [0, 1, 0.5] \]

### è®¡ç®—è¿‡ç¨‹ï¼š

1. å¯¹äº \( n = 0 \):
\[ (f * g)[0] = f[0] \cdot g[0] = 1 \cdot 0 = 0 \]

2. å¯¹äº \( n = 1 \):
\[ (f * g)[1] = f[0] \cdot g[1] + f[1] \cdot g[0] = 1 \cdot 1 + 2 \cdot 0 = 1 \]

3. å¯¹äº \( n = 2 \):
\[ (f * g)[2] = f[0] \cdot g[2] + f[1] \cdot g[1] + f[2] \cdot g[0] = 1 \cdot 0.5 + 2 \cdot 1 + 3 \cdot 0 = 0.5 + 2 + 0 = 2.5 \]

4. å¯¹äº \( n = 3 \):
\[ (f * g)[3] = f[1] \cdot g[2] + f[2] \cdot g[1] = 2 \cdot 0.5 + 3 \cdot 1 = 1 + 3 = 4 \]

5. å¯¹äº \( n = 4 \):
\[ (f * g)[4] = f[2] \cdot g[2] = 3 \cdot 0.5 = 1.5 \]

æ‰€ä»¥ï¼Œå·ç§¯ç»“æœæ˜¯ï¼š

\[ (f * g) = [0, 1, 2.5, 4, 1.5] \]

è¿™éªŒè¯äº†æˆ‘ä»¬ç”¨ Python ç¨‹åºè®¡ç®—å¾—åˆ°çš„ç»“æœæ˜¯æ­£ç¡®çš„ã€‚

### åº”ç”¨

- **ä¿¡å·å¤„ç†**ï¼šå·ç§¯ç”¨äºæ»¤æ³¢å™¨çš„è®¾è®¡å’Œåº”ç”¨ï¼Œä»¥å»é™¤å™ªå£°æˆ–æå–ç‰¹å®šä¿¡å·ç‰¹å¾ã€‚
- **å›¾åƒå¤„ç†**ï¼šå·ç§¯ç”¨äºè¾¹ç¼˜æ£€æµ‹ã€æ¨¡ç³Šå¤„ç†ç­‰ï¼Œé€šè¿‡å·ç§¯æ ¸ï¼ˆæ»¤æ³¢å™¨ï¼‰å¯¹å›¾åƒè¿›è¡Œæ“ä½œã€‚
- **æ·±åº¦å­¦ä¹ **ï¼šå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åˆ©ç”¨å·ç§¯å±‚æ¥æå–å›¾åƒç‰¹å¾ï¼Œå¹¿æ³›åº”ç”¨äºè®¡ç®—æœºè§†è§‰é¢†åŸŸã€‚

ç†è§£å·ç§¯éœ€è¦ä¸€å®šçš„æŠ½è±¡æ€ç»´ï¼Œä½†é€šè¿‡å®é™…ä¾‹å­å’Œåº”ç”¨åœºæ™¯ï¼Œå¯ä»¥æ›´ç›´è§‚åœ°æŒæ¡å…¶æ¦‚å¿µã€‚å¦‚æœè¿˜æœ‰å…·ä½“çš„ä¾‹å­æˆ–åº”ç”¨é—®é¢˜ï¼Œæ¬¢è¿è¿›ä¸€æ­¥è®¨è®ºï¼

[calculate convolution](../src/convolution.py)

ä½ è¯´å¾—å¯¹ï¼Œç¨‹åºä¸­å¹¶æ²¡æœ‰æ˜¾å¼åœ°å°† \(g\) ç¿»è½¬å’Œå¹³ç§»ã€‚ä¸è¿‡ï¼Œ`np.convolve` å‡½æ•°å†…éƒ¨å·²ç»å®ç°äº†è¿™äº›æ“ä½œã€‚

ä¸ºäº†æ›´æ¸…æ¥šåœ°ç†è§£å·ç§¯çš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥æ‰‹åŠ¨å®ç°ä¸€ä¸ªç®€å•çš„å·ç§¯å‡½æ•°ï¼Œè¿™æ ·å¯ä»¥çœ‹åˆ°ç¿»è½¬å’Œå¹³ç§»çš„æ­¥éª¤ã€‚ä»¥ä¸‹æ˜¯æ‰‹åŠ¨è®¡ç®—å·ç§¯çš„Pythonä»£ç ï¼š

[manualy convolution, wrong result](../src/convolution1.py)


è¿è¡Œè¿™ä¸ªç¨‹åºå°†ä¼šè¾“å‡ºï¼š

```
f: [1, 2, 3]
g: [0, 1, 0.5]
å·ç§¯ç»“æœ: [0.5, 2.0, 3.5, 3, 0]
```

è¿™ä¸ªæ‰‹åŠ¨å®ç°çš„å·ç§¯å‡½æ•°ä¼šæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œè®¡ç®—ï¼š

1. å°†åºåˆ— \(g\) ç¿»è½¬ã€‚
2. å¯¹æ¯ä¸ªä½ç½® \(i\)ï¼Œè®¡ç®—ç¿»è½¬å \(g\) ä¸ \(f\) åœ¨è¯¥ä½ç½®çš„é‡å éƒ¨åˆ†çš„ä¹˜ç§¯ä¹‹å’Œã€‚
3. å°†è¿™äº›ä¹˜ç§¯ä¹‹å’Œå­˜å‚¨åœ¨ç»“æœåºåˆ—ä¸­ã€‚

è¿™æ ·å¯ä»¥æ›´æ¸…æ¥šåœ°çœ‹åˆ°å·ç§¯è¿‡ç¨‹ä¸­çš„æ¯ä¸ªæ­¥éª¤ã€‚