{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/rongardF/tvdatafeed.git 'C:\\Users\\haozh\\AppData\\Local\\Temp\\pip-req-build-peletdpe'\n",
      "  Running command git rev-parse -q --verify 'sha^e6f6aaa7de439ac6e454d9b26d2760ded8dc4923'\n",
      "  Running command git fetch -q https://github.com/rongardF/tvdatafeed.git e6f6aaa7de439ac6e454d9b26d2760ded8dc4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rongardF/tvdatafeed.git@e6f6aaa7de439ac6e454d9b26d2760ded8dc4923\n",
      "  Cloning https://github.com/rongardF/tvdatafeed.git (to revision e6f6aaa7de439ac6e454d9b26d2760ded8dc4923) to c:\\users\\haozh\\appdata\\local\\temp\\pip-req-build-peletdpe\n",
      "  Resolved https://github.com/rongardF/tvdatafeed.git to commit e6f6aaa7de439ac6e454d9b26d2760ded8dc4923\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in d:\\workspace\\learntorch\\env\\lib\\site-packages (from tvdatafeed==2.1.0) (65.5.0)\n",
      "Requirement already satisfied: pandas in d:\\workspace\\learntorch\\env\\lib\\site-packages (from tvdatafeed==2.1.0) (2.2.2)\n",
      "Collecting websocket-client (from tvdatafeed==2.1.0)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in d:\\workspace\\learntorch\\env\\lib\\site-packages (from tvdatafeed==2.1.0) (2.32.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in d:\\workspace\\learntorch\\env\\lib\\site-packages (from pandas->tvdatafeed==2.1.0) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\workspace\\learntorch\\env\\lib\\site-packages (from pandas->tvdatafeed==2.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\workspace\\learntorch\\env\\lib\\site-packages (from pandas->tvdatafeed==2.1.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\workspace\\learntorch\\env\\lib\\site-packages (from pandas->tvdatafeed==2.1.0) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\workspace\\learntorch\\env\\lib\\site-packages (from requests->tvdatafeed==2.1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\workspace\\learntorch\\env\\lib\\site-packages (from requests->tvdatafeed==2.1.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\workspace\\learntorch\\env\\lib\\site-packages (from requests->tvdatafeed==2.1.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspace\\learntorch\\env\\lib\\site-packages (from requests->tvdatafeed==2.1.0) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\workspace\\learntorch\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->tvdatafeed==2.1.0) (1.16.0)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Building wheels for collected packages: tvdatafeed\n",
      "  Building wheel for tvdatafeed (pyproject.toml): started\n",
      "  Building wheel for tvdatafeed (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tvdatafeed: filename=tvdatafeed-2.1.0-py3-none-any.whl size=17640 sha256=cc052236eed9f0de6a8b168875fe00e7aa2e4c2d1ddb82f2bdce9f26f457dc02\n",
      "  Stored in directory: c:\\users\\haozh\\appdata\\local\\pip\\cache\\wheels\\06\\d0\\3a\\2db0b7be159028983122b5d008500238bff35af2f2c512931e\n",
      "Successfully built tvdatafeed\n",
      "Installing collected packages: websocket-client, tvdatafeed\n",
      "Successfully installed tvdatafeed-2.1.0 websocket-client-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/rongardF/tvdatafeed.git@e6f6aaa7de439ac6e454d9b26d2760ded8dc4923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tvdatafeed (from versions: none)\n",
      "ERROR: No matching distribution found for tvdatafeed\n"
     ]
    }
   ],
   "source": [
    "!pip install tvdatafeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NQ1!', <Interval.in_1_minute: '1'>, 'NQ1M')\n",
      "('NQ1!', <Interval.in_5_minute: '5'>, 'NQ5M')\n",
      "('NQ1!', <Interval.in_30_minute: '30'>, 'NQ30M')\n",
      "('NQ1!', <Interval.in_4_hour: '4H'>, 'NQ4H')\n",
      "('NQ1!', <Interval.in_daily: '1D'>, 'NQ1D')\n",
      "('ES1!', <Interval.in_1_minute: '1'>, 'ES1M')\n",
      "('ES1!', <Interval.in_5_minute: '5'>, 'ES5M')\n",
      "('ES1!', <Interval.in_30_minute: '30'>, 'ES30M')\n",
      "('ES1!', <Interval.in_4_hour: '4H'>, 'ES4H')\n",
      "('ES1!', <Interval.in_daily: '1D'>, 'ES1D')\n"
     ]
    }
   ],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "# Input data\n",
    "futures = [\"NQ\", \"ES\"]\n",
    "periods = [\n",
    "    {Interval.in_1_minute: \"1M\"},\n",
    "    {Interval.in_5_minute: \"5M\"},\n",
    "    {Interval.in_30_minute: \"30M\"},\n",
    "    {Interval.in_4_hour: \"4H\"},\n",
    "    {Interval.in_daily: \"1D\"}\n",
    "]\n",
    "\n",
    "# Create the desired output items list\n",
    "items = []\n",
    "for future in futures:\n",
    "    for period_dict in periods:\n",
    "        for interval, suffix in period_dict.items():\n",
    "            # Construct the required format for each future-period combination\n",
    "            items.append((f\"{future}1!\", interval, f\"{future}{suffix}\"))\n",
    "\n",
    "# Print the items\n",
    "for item in items:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "# without user name and password\n",
    "tv = TvDatafeed()\n",
    "\n",
    "# df = tv.get_hist(symbol='NQ1!', exchange='CME_MINI', interval=Interval.in_1_minute, n_bars=100000)\n",
    "# df = df.reset_index()\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///data/ESNQ_DB.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_importer (df, table_name):\n",
    "    # Use inspector to check if the table exists\n",
    "    inspector = inspect(engine)\n",
    "    if not inspector.has_table(table_name):\n",
    "        df.to_sql(table_name, engine, if_exists='append')\n",
    "        print (f'New table created for {table_name} with {str(len(df))} rows')\n",
    "    else:\n",
    "        max_date = pd.read_sql(f'SELECT MAX(datetime) FROM {table_name}', engine).values[0][0]\n",
    "        print(max_date)\n",
    "        df = df[df.datetime > max_date]\n",
    "        df.to_sql(table_name, engine, if_exists='append')\n",
    "        print(str(len(df)) + ' new rows imported to DB ' + f'{table_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-08 14:54:00.000000\n",
      "11341 new rows imported to DB NQ1M\n",
      "2024-10-08 14:50:00.000000\n",
      "3110 new rows imported to DB NQ5M\n",
      "2024-10-08 14:30:00.000000\n",
      "519 new rows imported to DB NQ30M\n",
      "2024-10-08 13:00:00.000000\n",
      "68 new rows imported to DB NQ4H\n",
      "2024-10-07 17:00:00.000000\n",
      "12 new rows imported to DB NQ1D\n",
      "2024-10-08 14:54:00.000000\n",
      "15080 new rows imported to DB ES1M\n",
      "2024-10-08 14:50:00.000000\n",
      "3110 new rows imported to DB ES5M\n",
      "2024-10-08 14:30:00.000000\n",
      "519 new rows imported to DB ES30M\n",
      "2024-10-08 13:00:00.000000\n",
      "68 new rows imported to DB ES4H\n",
      "2024-10-07 17:00:00.000000\n",
      "12 new rows imported to DB ES1D\n"
     ]
    }
   ],
   "source": [
    "for item in items:\n",
    "    df = tv.get_hist(symbol=item[0], exchange='CME_MINI', interval=item[1], n_bars=100000)\n",
    "    df = df.reset_index()\n",
    "    sql_importer(df, item[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
